---
title: 爬虫基础
date: 2018-04-30 14:04:50
tags:
     - 爬虫
---





# 获取源码



## requests



#### GET请求

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests
response = requests.get('https://www.mi.com/')

# 查看响应状态码
print(response.status_code)

# 查看响应状态文本
print(response.reason)

# 查看响应内容
print(response.text)

# 查看二进制的响应内容
print(response.content)

# 返回响应编码
print(response.encoding)

# 返回头部信息
print(response.headers)

# 返回的最终url
print(response.url)

# 返回的cookies
print(response.cookies)
```



##### 带参数的GET请求

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests

data = {'name': 'huangke', 'gender': 'male'}
r = requests.get('http://httpbin.org/get', params=data)
# print(r.text)

print(r.url)

# 'a返回的结果 http://httpbin.org/get?key1=value1&key2=value2
```



##### GET解析json

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests
response = requests.get('https://github.com/timeline.json')

print(response.json())
print(type(response.json()))

print(response.text)
print(type(response.text))


# 获取到json数据不意味着就得到了正确的结果，还应该同时确认status_code才行
print(response.status_code)
```



##### GET解析二进制数据

```python
# 以请求返回的二进制数据创建一张图片，比如下下载一张menghia的图片

#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests

response = requests.get('http://f.fwallpapers.com/images/catrinel-menghia-10.jpg')
img = response.content

with open('menghia.jpg', 'wb') as f:
    f.write(img)
```



##### GET添加headers

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests

headers = {'User-Agent': 'Mozilla/4.0 (compatible; IBrowse 3.0; AmigaOS4.0)'}
response = requests.get('https://www.zhihu.com/explore', headers=headers)

print(response.status_code)
```



##### POST请求

POST请求同GET基本一样，把get替换为post即可



##### 判断请求是否成功

```python
assert (response.status_code == requests.codes.ok)	
```



##### 上传文件

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests

hello = {'hellofile': open('hello.py', 'rb')}
response = requests.post("http://httpbin.org/post", files=hello)
print(response.text)

```



##### 获取cookies

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests

headers = {'User-Agent': 'Mozilla/4.0 (compatible; IBrowse 3.0; AmigaOS4.0)'}
r = requests.get('https://www.zhihu.com/explore', headers=headers)

for k, v in r.cookies.items():
    print(k + '=' + v)
```



##### 会话维持

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import requests

s = requests.session()
s.get('http://httpbin.org/cookies/set/number/123456')
response = s.get('http://httpbin.org/cookies')
print(response.text)
```



##### 证书认证

```python
import requests

# 直接访问无法通过证书验证，提示需要SSL
r = requests.get('https://www.12306.cn')
print(r.status_code)

# 将verify设置为False后，可以通过，但是仍有提示
r = requests.get('https://www.12306.cn', verify=False)
print(r.status_code)
```



##### 代理

```python
import requests

proxies = {
    'http':"http://127.0.0.1:9743",
    'https':'https://127.0.0.1:9743',
}

response = requests.get("http://www.taobao.com", proxies = proxies)
print(response.status_code)
# to be done 
```



##### 超时设置

```python
import requests

try:
    r = requests.get('https://www.taobao.com', timeout=1)
    print(r.status_code)
except Exception as e:
    print(e)
```



##### 认证

```python
import requests
from requests.auth import HTTPBasicAuth

r = requests.get("http://120.27/34/24:9001", auth=HTTPBasicAuth('user', '123'))
print(r.status_code)
```



##### 异常处理

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-


import requests
from requests.exceptions import ReadTimeout, ConnectionError, RequestException

try:
    r = requests.get("http://www.baidu.com", timeout=0.02)
    print(r.status_code)
except ReadTimeout:
    print('Timeout')
except ConnectionError:
    print("Connection error")
except RequestException:
    print('Error')
```



## 解决乱码

```python
import requests
import chardet

r = requests.get('http://www.baidu.com')
print(chardet.detect(r.content))
r.encoding = chardet.detect(r.content)['encoding']
print(r.text)
```

