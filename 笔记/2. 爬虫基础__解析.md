#BeautifulSoup



> 使用方法，推荐用'lxml'
>

```python
import requests
from bs4 import BeautifulSoup

html = requests.get('http://182.140.237.75/test.html')
html.encoding = 'utf-8'			                # 显示指定获取的html页面编码为utf-8
soup = BeautifulSoup(html.text, 'lxml')

print((soup.prettify()))
```





## 获取tag

> soup.tag 即可获取这些标签的内容，不过这只能找到第一个

```python
# 取出title部分
print(soup.title)

# 取出<head>部分
print(soup.head)

# 取出body部分
print(soup.body)

# 取出标签的名称
print(soup.title.name)

# 取出标签中的内容
print(soup.title.string)
print(soup.title.text)
print(soup.title.get_text())

# 从文档中取得所有文字的内容
print(soup.text)
print(soup.get_text())


print(soup.title)
# <title>花瓣网_陪你做生活的设计师（发现、采 ... 美图、商品等）</title>

print(soup.head)
# <head> <meta charset="utf-8"/> <meta content="IE=edge,chrome=1" ... </head>

print(soup.a)
# <a class="off" id="elevator" onclick="return false;" title="回到顶部"></a>

print(soup.div)
# <div class="page-min-width" id="page"></div>
```



## 获取Tag的名字：

1. Name属性

   ```python
   # 即tag的名称
   
   print(soup.title.name)
   # title
   
   print(soup.a.name)
   # a
   ```

2. Attrs属性

   ```python
   # <a class="off" id="elevator" onclick="return false;" title="回到顶部"></a>
   ```



   ## 获取Tag的属性



- 获取所有属性

  ```python
  print(soup.a.attrs)   
     
  {'id': 'elevator', 'class': ['off'], 'onclick': 'return false;', 'title': '回到顶部'}
  ```

- 获取属性的值

  1.  取出a标签的id属性

     ```python
     print(soup.a['id'])
     # elevator
     ```

  2. 取出a标签的class属性

     ```python
     
     print(soup.a['class'][0])
     # off  # 此处注意，class获取的是一个列表 
     ```





获取标签内的文字

## 获取tag里的文字

- tag.string

  ```python
  # <title>花瓣网_陪你做生活的设计师（发现、采集你喜欢的灵感、家居、穿搭、旅行、美图、商品等）</title>
  
  print(soup.title.string)
  # 花瓣网_陪你做生活的设计师（发现、采集你喜欢的灵感、家居、穿搭、旅行、美图、商品等）
  ```

- tag.get_text()

  ```python
  #.get_text() 会把你正在处理的 HTML 文档中所有的标签都清除，然后返回 一个只包含文字的字符串
  ```


   





## 标签查找

- ###### find   

- ###### find_all 

> 通过标签的不同属性轻松地过滤 HTML 页面，查找需要的标签组或单个标签。 
>
> ```python
> findAll(tag, attributes, recursive, text, limit, keywords)
> find(tag, attributes, recursive, text, keywords)
> ```



#### 查找一个tag

```python
.findAll("h1")
```



#### 查找多个tag

```python
.findAll({"h1","h2","h3","h4","h5","h6"})
```



#### 根据属性查找

```python
.findAll("span", {"class":"green"})
.findAll("span", {"class":{"green", "red"}})
```



#### 根据属性值去查找

```python
bsObj.findAll(class_="green")

allText = bsObj.findAll(id="text")
print(soup.find_all(id='elevator'))
print(soup.find_all(class_='off'))   
```



## CSS选择器查找

> select()方法返回的结果都是列表形式，可以遍历，然后使用get_text()方法来获取内容 



#### 通过标签名



```python
print(soup.select("tag_name"))


```



#### 通过类名查找

```html
<div class="job-name" title="系统集成项目经理">
    <div class="company">成都旋极研发中心招聘</div>
    <span class="name">系统集成项目经理</span>
    <div class="marEdit">
    </div>
</div>
```



```python
print(soup.select(".class_name"))

job_name = soup.select_one(".position-content .job-name .name").string
comp_name = soup.select_one(".position-content .job-name .company").string
```



#### 通过id查找
```python
print(soup.select("#id_name"))
```



#### 组合查找
```python
print(soup.select("tag #id_name"))
```



#### 通过属性值查找

```html
<span class="salary">8k-15k </span>
```



```python
# css
salary = soup.select_one(".salary")
salary = soup.select_one("span[class='salary']").string
salary = soup.select("span[class='salary']")[0].string

# find
name = soup.find("span",class_='salary')

# 取出 8k-15k

# 获取class名 
soup.tag['class']
name = soup.select_one("span[class='salary']")['class']
```



#### 选某个节点下所有某子节点

```html
<dd class="job_request">
    <p>
        <span class="salary">8k-15k </span>
        <span>/成都 /</span>
        <span>经验3-5年 /</span>
        <span>本科及以上 /</span>
        <span>全职</span>
    </p>
    <!-- 职位标签 -->
    <ul class="position-label clearfix">
        <li class="labels">系统集成</li>
    </ul>
    <p class="publish_time">2018-08-29&nbsp; 发布于拉勾网</p>
</dd>
```

```python
name = soup.select(".job_request span")
```



## 通过正则表达式查找

```python
soup.find_all(re.compile(pattern))
```





# Xpath 解析



