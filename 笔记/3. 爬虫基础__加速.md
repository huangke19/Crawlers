## 多线程

```python
    threads = []
    for i in range(1, pages + 1):
        t = threading.Thread(target=main, args=(keyword, i))
        threads.append(t)

    for t in threads:
        t.start()
        time.sleep(15)  # 此处临时设置为这样，正式爬的时候线程全部启动，每个线程各取一个IP

    for t in threads:
        t.join()
```



## 进程池

```python
    import os
    from multiprocessing import Process, Pool
    from time import sleep

    def run_task(name):
        print('Child process %s (%s) is Running ... ' % (name, os.getpid()))
        sleep(1)

    if __name__ == '__main__':
        print('Current process %s.' % os.getpid())
        p = Pool(processes=3)
        for i in range(5):
            p.apply_async(run_task, args=(i,))
        print('Waiting for all subprocesses done... ')
        p.close()
        p.join()
        print('All subprocesses done.')
```



## 协程

```python
async def crawl(_id, sem):
    async with sem:
        try:
            html = await  get_page(_id)
            data = parse_page(html)
            await save_to_redis(data)
        except Exception as e:
            print(e)

if __name__ == '__main__':
    loop = asyncio.get_event_loop()

    sem = asyncio.Semaphore(1024)  # 维持1024个信号量
    tasks = [asyncio.ensure_future(crawl(i, sem)) for i in range(1, 13426)]
    loop.run_until_complete(asyncio.wait(tasks))
    loop.close()
```

